# üï∑Ô∏è –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ó–∞–ø—É—Å–∫—É –ü–∞—Ä—Å–µ—Ä–æ–≤

## üéØ –ë—ã—Å—Ç—Ä—ã–π –°—Ç–∞—Ä—Ç

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ü—Ä–æ—Å—Ç–æ–π –ó–∞–ø—É—Å–∫ (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–µ—Ä Habr (10 —Å—Ç–∞—Ç–µ–π)
python run_scraper.py

# –° –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python run_scraper.py 50                    # 50 —Å—Ç–∞—Ç–µ–π
python run_scraper.py 30 "python,devops"    # 30 —Å—Ç–∞—Ç–µ–π –∏–∑ —Ö–∞–±–æ–≤
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: CLI —Å Rich Progress

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install click rich

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ CLI
python cli.py scrape habr --limit 20
python cli.py scrape habr --limit 50 --hubs "python,machine_learning"
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: –ß–µ—Ä–µ–∑ Docker

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
docker-compose exec api python run_scraper.py 20

# –ò–ª–∏ —á–µ—Ä–µ–∑ CLI
docker-compose exec api python cli.py scrape habr --limit 30
```

---

## üìñ –î–µ—Ç–∞–ª—å–Ω–æ–µ –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞

```bash
# –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –ë–î –∑–∞–ø—É—â–µ–Ω–∞
docker-compose up -d postgres

# –ò–ª–∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
psql postgresql://newsaggregator:changeme123@localhost:5433/news_aggregator
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -r requirements.txt
```

–ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–∞–∫–µ—Ç—ã:
- `beautifulsoup4` - –ø–∞—Ä—Å–∏–Ω–≥ HTML
- `lxml` - –±—ã—Å—Ç—Ä—ã–π –ø–∞—Ä—Å–µ—Ä
- `aiohttp` - –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã
- `click` - CLI framework
- `rich` - –∫—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å

### 3. –ó–∞–ø—É—Å–∫ –ü–∞—Ä—Å–µ—Ä–∞

#### –°–ø–æ—Å–æ–± A: –ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç

```bash
# –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫ (10 —Å—Ç–∞—Ç–µ–π)
python run_scraper.py

# 50 —Å—Ç–∞—Ç–µ–π
python run_scraper.py 50

# 30 —Å—Ç–∞—Ç–µ–π –∏–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ö–∞–±–æ–≤
python run_scraper.py 30 "python,devops,docker"
```

**–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:**
```
üöÄ –ó–∞–ø—É—Å–∫ Habr –ø–∞—Ä—Å–µ—Ä–∞
   –õ–∏–º–∏—Ç: 10
   –•–∞–±—ã: –≤—Å–µ

‚úÖ –ì–æ—Ç–æ–≤–æ!
   –°–æ–±—Ä–∞–Ω–æ: 10
   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: 8
   –î—É–±–ª–∏–∫–∞—Ç–æ–≤: 2
   –û—à–∏–±–æ–∫: 0
```

#### –°–ø–æ—Å–æ–± B: CLI —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º

```bash
# –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—É—Å–∫
python cli.py scrape habr --limit 10

# –° —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ —Ö–∞–±–∞–º
python cli.py scrape habr --limit 50 --hubs "python,javascript"

# –¢–æ–ª—å–∫–æ –∏–∑ —Ö–∞–±–∞ Python
python cli.py scrape habr --limit 20 --hubs "python"
```

**–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:**
```
üöÄ –ó–∞–ø—É—Å–∫ Habr –ø–∞—Ä—Å–µ—Ä–∞
–õ–∏–º–∏—Ç: 20
–•–∞–±—ã: python

–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç–∞—Ç–µ–π... ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100% 20/20

‚úÖ –ì–æ—Ç–æ–≤–æ!
–°–æ–±—Ä–∞–Ω–æ: 20
–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: 18
–î—É–±–ª–∏–∫–∞—Ç–æ–≤: 2
–û—à–∏–±–æ–∫: 0
```

#### –°–ø–æ—Å–æ–± C: –ò–∑ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
docker-compose exec api python run_scraper.py 15

# –° —Ö–∞–±–∞–º–∏
docker-compose exec api python run_scraper.py 30 "python,devops"

# –ß–µ—Ä–µ–∑ CLI
docker-compose exec api python cli.py scrape habr --limit 25
```

### 4. –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –ó–∞–ø—É—Å–∫ (Python API)

```python
import asyncio
from src.scrapers.habr.scraper_service import HabrScraperService

async def main():
    """–ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∑–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞."""
    service = HabrScraperService()
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–∏–Ω–≥
    results = await service.scrape_and_save(
        limit=20,
        hubs=['python', 'devops']
    )
    
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {results['saved']}")
    print(f"–î—É–±–ª–∏–∫–∞—Ç–æ–≤: {results['duplicates']}")

# –ó–∞–ø—É—Å–∫
asyncio.run(main())
```

### 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```bash
# –ß–µ—Ä–µ–∑ psql
psql postgresql://newsaggregator:changeme123@localhost:5433/news_aggregator

# SQL –∑–∞–ø—Ä–æ—Å—ã
SELECT COUNT(*) FROM articles;
SELECT title, author, created_at FROM articles ORDER BY created_at DESC LIMIT 10;
SELECT * FROM articles WHERE source = 'habr';
```

**–ò–ª–∏ —á–µ—Ä–µ–∑ API:**
```bash
# –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å—Ç–∞—Ç—å–∏
curl http://localhost:8000/api/v1/articles/

# –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5
curl "http://localhost:8000/api/v1/articles/?limit=5"
```

---

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ü–∞—Ä—Å–µ—Ä–∞

### –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –¢–∏–ø | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|--------------|----------|
| `limit` | int | 10 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π |
| `hubs` | str | "" | –•–∞–±—ã —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é |
| `progress_callback` | callable | None | –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ |

### –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

```bash
# 100 —Å—Ç–∞—Ç–µ–π
python run_scraper.py 100

# –ò–∑ —Ç–æ–ø —Ö–∞–±–æ–≤
python run_scraper.py 50 "python,javascript,devops,docker,kubernetes"

# –¢–æ–ª—å–∫–æ Python
python run_scraper.py 30 "python"
```

---

## üîß –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ö–∞—Å—Ç–æ–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
import asyncio
from src.scrapers.habr.scraper_service import HabrScraperService

async def scrape_with_progress():
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º."""
    service = HabrScraperService()
    
    count = 0
    def progress():
        nonlocal count
        count += 1
        print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {count}")
    
    results = await service.scrape_and_save(
        limit=50,
        hubs=['python'],
        progress_callback=progress
    )
    
    print(f"\n–ò—Ç–æ–≥–æ: {results['saved']} —Å—Ç–∞—Ç–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")

asyncio.run(scrape_with_progress())
```

### –§–æ–Ω–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ (Celery-style)

```python
# tasks.py
import asyncio
from src.scrapers.habr.scraper_service import HabrScraperService

async def background_scrape():
    """–§–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞."""
    service = HabrScraperService()
    
    while True:
        # –ü–∞—Ä—Å–∏—Ç—å –∫–∞–∂–¥—ã–π —á–∞—Å
        results = await service.scrape_and_save(limit=20)
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {results['saved']}")
        
        # –ü–æ–¥–æ–∂–¥–∞—Ç—å 1 —á–∞—Å
        await asyncio.sleep(3600)

# –ó–∞–ø—É—Å–∫
asyncio.run(background_scrape())
```

---

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: "Connection refused" –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ë–î

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ PostgreSQL –∑–∞–ø—É—â–µ–Ω
docker-compose ps postgres

# –ï—Å–ª–∏ –Ω–µ—Ç - –∑–∞–ø—É—Å—Ç–∏—Ç—å
docker-compose up -d postgres

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
psql postgresql://newsaggregator:changeme123@localhost:5433/news_aggregator -c "SELECT version();"
```

### –ü—Ä–æ–±–ª–µ–º–∞: "Table does not exist"

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ë–î
docker-compose exec postgres psql -U newsaggregator -d news_aggregator -f /docker-entrypoint-initdb.d/init.sql

# –ò–ª–∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –º–∏–≥—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ Alembic)
alembic upgrade head
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ü–∞—Ä—Å–µ—Ä –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç —Å—Ç–∞—Ç—å–∏

**–†–µ—à–µ–Ω–∏–µ:**
- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–Ω—Ç–µ—Ä–Ω–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
- –í–æ–∑–º–æ–∂–Ω–æ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ HTML –Ω–∞ Habr
- –û–±–Ω–æ–≤–∏—Ç—å —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –≤ `scraper_service.py`

### –ü—Ä–æ–±–ª–µ–º–∞: "Already exists" –æ—à–∏–±–∫–∏

**–†–µ—à–µ–Ω–∏–µ:**
–≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –ø–∞—Ä—Å–µ—Ä –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL.
–î—É–±–ª–∏–∫–∞—Ç—ã —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è –≤ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ.

---

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

```python
import logging

# –í–∫–ª—é—á–∏—Ç—å debug –ª–æ–≥–∏
logging.basicConfig(level=logging.DEBUG)

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä—Å–µ—Ä
python run_scraper.py 10
```

### –ú–µ—Ç—Ä–∏–∫–∏

```python
# –ü–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
results = await service.scrape_and_save(limit=100)

print(f"–£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {results['saved'] / results['scraped'] * 100:.1f}%")
print(f"–î—É–±–ª–∏–∫–∞—Ç–æ–≤: {results['duplicates']}")
print(f"–û—à–∏–±–æ–∫: {results['errors']}")
```

---

## üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è

### Cron Job (Linux)

```bash
# –î–æ–±–∞–≤–∏—Ç—å –≤ crontab
crontab -e

# –ü–∞—Ä—Å–∏—Ç—å –∫–∞–∂–¥—ã–π —á–∞—Å
0 * * * * cd /path/to/project && python run_scraper.py 20 >> /var/log/scraper.log 2>&1

# –ü–∞—Ä—Å–∏—Ç—å –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
0 */6 * * * cd /path/to/project && python run_scraper.py 50 "python,devops"
```

### Systemd Service (Linux)

```ini
# /etc/systemd/system/news-scraper.service
[Unit]
Description=News Aggregator Scraper
After=network.target

[Service]
Type=simple
User=www-data
WorkingDirectory=/path/to/project
ExecStart=/usr/bin/python3 run_scraper.py 30
Restart=always
RestartSec=3600

[Install]
WantedBy=multi-user.target
```

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å
sudo systemctl start news-scraper
sudo systemctl enable news-scraper
```

### n8n Workflow

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π n8n –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏:

1. –û—Ç–∫—Ä–æ–π—Ç–µ http://localhost:5678
2. –°–æ–∑–¥–∞–π—Ç–µ workflow:
   - Schedule Trigger (–∫–∞–∂–¥—ã–π —á–∞—Å)
   - Execute Command: `python run_scraper.py 20`
3. –ê–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ workflow

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ

### –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–µ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞

```python
# src/scrapers/medium/scraper_service.py
from src.scrapers.base_scraper import BaseScraper

class MediumScraperService(BaseScraper):
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è Medium."""
    
    async def scrape_articles(self, limit: int):
        # –í–∞—à–∞ –ª–æ–≥–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞
        pass
```

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –¥—Ä—É–≥–∏–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏

–°–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã:
- `src/scrapers/habr/` - Habr
- `src/scrapers/telegram/` - Telegram (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)
- `src/scrapers/reddit/` - Reddit (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)

---

## ‚úÖ Checklist

- [ ] PostgreSQL –∑–∞–ø—É—â–µ–Ω
- [ ] –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã (`pip install -r requirements.txt`)
- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
- [ ] –ó–∞–ø—É—â–µ–Ω –ø–µ—Ä–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥ (`python run_scraper.py`)
- [ ] –ü—Ä–æ–≤–µ—Ä–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î
- [ ] –ù–∞—Å—Ç—Ä–æ–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

**–ì–æ—Ç–æ–≤–æ! üéâ**

–ù–∞—á–Ω–∏—Ç–µ —Å: `python run_scraper.py 10`
