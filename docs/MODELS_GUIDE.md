# ü§ñ –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –ú–æ–¥–µ–ª—è–º Ollama

## üì¶ –ö–∞–∫–∏–µ –ú–æ–¥–µ–ª–∏ –ù—É–∂–Ω—ã

### ‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ (–ú–∏–Ω–∏–º—É–º)

#### 1. **Mistral** (~4.1 GB)
```bash
docker-compose exec ollama ollama pull mistral:latest
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- ‚úÖ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (–Ω–æ–≤–æ—Å—Ç—å/—Å—Ç–∞—Ç—å—è)
- ‚úÖ –û—Ü–µ–Ω–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
- ‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
- ‚úÖ –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö°‚ö°‚ö° –ë—ã—Å—Ç—Ä–∞—è
- –ö–∞—á–µ—Å—Ç–≤–æ: ‚≠ê‚≠ê‚≠ê –•–æ—Ä–æ—à–µ–µ
- RAM: ~4-6 GB

---

### ‚≠ê –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ

#### 2. **Llama 3** (~4.7 GB)
```bash
docker-compose exec ollama ollama pull llama3:latest
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- ‚úÖ –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (–ª—É—á—à–µ —á–µ–º Mistral)
- ‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö°‚ö° –°—Ä–µ–¥–Ω—è—è
- –ö–∞—á–µ—Å—Ç–≤–æ: ‚≠ê‚≠ê‚≠ê‚≠ê –û—Ç–ª–∏—á–Ω–æ–µ
- RAM: ~6-8 GB

---

### üî• –î–ª—è –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ö–∞—á–µ—Å—Ç–≤–∞

#### 3. **DeepSeek R1 20B** (~13 GB)
```bash
docker-compose exec ollama ollama pull deepseek-r1:20b
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
- ‚úÖ –í–°–Å (–ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
- ‚úÖ –°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏
- ‚úÖ Reasoning

**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:**
- –°–∫–æ—Ä–æ—Å—Ç—å: ‚ö° –ú–µ–¥–ª–µ–Ω–Ω–∞—è (~30-60 —Å–µ–∫ –Ω–∞ –∑–∞–¥–∞—á—É)
- –ö–∞—á–µ—Å—Ç–≤–æ: ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ
- RAM: ~20-24 GB (–í–ê–ñ–ù–û!)

**‚ö†Ô∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –ú–∏–Ω–∏–º—É–º 20 GB RAM
- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è GPU

---

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –í—Å–µ—Ö –ú–æ–¥–µ–ª–µ–π

### –°–ø–æ—Å–æ–± 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –°–∫—Ä–∏–ø—Ç (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

```bash
# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫—Ä–∏–ø—Ç
./install_models.sh

# –û–Ω —É—Å—Ç–∞–Ω–æ–≤–∏—Ç:
# 1. mistral:latest
# 2. llama3:latest
# 3. –°–ø—Ä–æ—Å–∏—Ç –ø—Ä–æ deepseek-r1:20b
```

### –°–ø–æ—Å–æ–± 2: –í—Ä—É—á–Ω—É—é

```bash
# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ
docker-compose exec ollama ollama pull mistral:latest
docker-compose exec ollama ollama pull llama3:latest

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ (–µ—Å–ª–∏ –µ—Å—Ç—å RAM)
docker-compose exec ollama ollama pull deepseek-r1:20b
```

### –°–ø–æ—Å–æ–± 3: –ü—Ä–∏ –°–±–æ—Ä–∫–µ Docker (–ú–µ–¥–ª–µ–Ω–Ω–æ)

```bash
# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ docker/ollama/Dockerfile
# –ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å:
docker-compose build ollama
docker-compose up -d ollama
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ú–æ–¥–µ–ª–µ–π

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | –°–∫–æ—Ä–æ—Å—Ç—å | –ö–∞—á–µ—Å—Ç–≤–æ | RAM | –ó–∞–¥–∞—á–∏ |
|--------|--------|----------|----------|-----|--------|
| **Mistral** | 4.1 GB | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 4-6 GB | –í—Å–µ –±–∞–∑–æ–≤—ã–µ |
| **Llama 3** | 4.7 GB | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 6-8 GB | –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è |
| **DeepSeek R1** | 13 GB | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 20+ GB | –°–ª–æ–∂–Ω—ã–µ |

---

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ú–æ–¥–µ–ª–µ–π –≤ –ê–≥–µ–Ω—Ç–∞—Ö

### –ü–æ –£–º–æ–ª—á–∞–Ω–∏—é (–¢–µ–∫—É—â–∞—è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)

```python
# src/application/ai_services/agents/

classifier_agent.py:    model="mistral:latest"
relevance_agent.py:     model="mistral:latest"
summarizer_agent.py:    model="mistral:latest"  # ‚Üê –ò–°–ü–†–ê–í–õ–ï–ù–û
rewriter_agent.py:      model="mistral:latest"
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Llama 3 –¥–ª—è –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏

```python
# src/application/ai_services/agents/summarizer_agent.py

response = self.ollama.generate(
    prompt=prompt,
    model="llama3:latest",  # ‚Üê –ò–∑–º–µ–Ω–∏—Ç—å –Ω–∞ llama3
    temperature=0.7,
    max_tokens=150
)
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DeepSeek R1 –¥–ª—è –í—Å–µ–≥–æ

```python
# –í–æ –≤—Å–µ—Ö –∞–≥–µ–Ω—Ç–∞—Ö –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞:
model="deepseek-r1:20b"
```

**‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ:** DeepSeek –û–ß–ï–ù–¨ –º–µ–¥–ª–µ–Ω–Ω—ã–π (~30-60 —Å–µ–∫ –Ω–∞ –∑–∞–¥–∞—á—É)

---

## üíæ –ì–¥–µ –•—Ä–∞–Ω—è—Ç—Å—è –ú–æ–¥–µ–ª–∏

```bash
# Docker volume
ollama_data:/root/.ollama

# –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –º–µ–∂–¥—É –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–º–∏!
# –°–∫–∞—á–∏–≤–∞—Ç—å –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –û–î–ò–ù –†–ê–ó
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞

```bash
# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
docker-compose exec ollama ollama list

# –†–∞–∑–º–µ—Ä volume
docker volume inspect ollama_data

# –£–¥–∞–ª–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏ (–æ—á–∏—Å—Ç–∏—Ç—å volume)
docker-compose down
docker volume rm news-aggregator-pro_ollama_data
```

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

### –î–ª—è –†–∞–∑—Ä–∞–±–æ—Ç–∫–∏
```
mistral:latest
```
- –ë—ã—Å—Ç—Ä–æ
- –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- –ú–∞–ª–æ RAM

### –î–ª—è Production
```
mistral:latest + llama3:latest
```
- –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞
- Mistral –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- Llama3 –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏

### –î–ª—è –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ö–∞—á–µ—Å—Ç–≤–∞
```
deepseek-r1:20b
```
- –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
- –¢—Ä–µ–±—É–µ—Ç –º–æ—â–Ω—ã–π —Å–µ—Ä–≤–µ—Ä
- –ú–µ–¥–ª–µ–Ω–Ω–æ (~5-10x –º–µ–¥–ª–µ–Ω–Ω–µ–µ Mistral)

---

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –° Mistral
```
1 —Å—Ç–∞—Ç—å—è: ~20-30 —Å–µ–∫
10 —Å—Ç–∞—Ç–µ–π: ~3-5 –º–∏–Ω—É—Ç
100 —Å—Ç–∞—Ç–µ–π: ~30-50 –º–∏–Ω—É—Ç
```

### –° Llama 3
```
1 —Å—Ç–∞—Ç—å—è: ~30-40 —Å–µ–∫
10 —Å—Ç–∞—Ç–µ–π: ~5-7 –º–∏–Ω—É—Ç
100 —Å—Ç–∞—Ç–µ–π: ~50-70 –º–∏–Ω—É—Ç
```

### –° DeepSeek R1 20B
```
1 —Å—Ç–∞—Ç—å—è: ~60-120 —Å–µ–∫
10 —Å—Ç–∞—Ç–µ–π: ~10-20 –º–∏–Ω—É—Ç
100 —Å—Ç–∞—Ç–µ–π: ~100-200 –º–∏–Ω—É—Ç
```

---

## üîß –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ü—Ä–æ–±–ª–µ–º

### –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å
docker-compose exec ollama ollama pull mistral:latest

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
docker-compose exec ollama ollama list
```

### –ù–µ—Ö–≤–∞—Ç–∫–∞ –ø–∞–º—è—Ç–∏
```bash
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
# mistral –≤–º–µ—Å—Ç–æ llama3
# llama3 –≤–º–µ—Å—Ç–æ deepseek-r1

# –ò–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å RAM/swap
```

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞
```bash
# 1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å
# 2. –£–º–µ–Ω—å—à–∏—Ç—å max_tokens –≤ –∞–≥–µ–Ω—Ç–∞—Ö
# 3. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU (–µ—Å–ª–∏ –µ—Å—Ç—å)
```

---

## ‚úÖ –ë—ã—Å—Ç—Ä—ã–π –°—Ç–∞—Ä—Ç

```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–¥–µ–ª–∏
./install_models.sh

# 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å
docker-compose exec ollama ollama list

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç
docker-compose exec api python run_full_pipeline.py 1

# 4. –ì–æ—Ç–æ–≤–æ! üöÄ
```

---

## üéì –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ

### –î—Ä—É–≥–∏–µ –ü–æ–ª–µ–∑–Ω—ã–µ –ú–æ–¥–µ–ª–∏

```bash
# Phi-3 (–º–∞–ª–∞—è, –±—ã—Å—Ç—Ä–∞—è)
ollama pull phi3:mini

# Gemma 2 (–æ—Ç Google)
ollama pull gemma2

# Qwen (–∫–∏—Ç–∞–π—Å–∫–∞—è, —Ö–æ—Ä–æ—à–∞ –¥–ª—è –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç–∏)
ollama pull qwen2
```

### GPU –£—Å–∫–æ—Ä–µ–Ω–∏–µ

–ï—Å–ª–∏ –µ—Å—Ç—å NVIDIA GPU:
```bash
# Docker –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å:
docker-compose exec ollama nvidia-smi
```

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

- Ollama: https://ollama.ai/
- –ú–æ–¥–µ–ª–∏: https://ollama.ai/library
- DeepSeek R1: https://github.com/deepseek-ai/DeepSeek-R1
