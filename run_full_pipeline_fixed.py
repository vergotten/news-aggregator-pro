#!/usr/bin/env python3
"""
–ü–æ–ª–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç–µ–π - Production-Ready –≤–µ—Ä—Å–∏—è —Å OpenRouter.

–í–µ—Ä—Å–∏—è 3.4.0:
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å CreateArticleCommand (—Ä–∞–∑–Ω—ã–µ –≤–µ—Ä—Å–∏–∏)
- –°–º—è–≥—á—ë–Ω–Ω—ã–π QualityValidator
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ OpenRouter –∏ Ollama
"""

import asyncio
import sys
import time
import logging
import os
from datetime import datetime
from typing import Optional, Dict, Any
import uuid

# –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
try:
    from tqdm import tqdm

    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

from src.scrapers.habr.scraper_service import HabrScraperService
from src.application.ai_services.orchestrator import AIOrchestrator
from src.infrastructure.ai.qdrant_client import QdrantService
from src.infrastructure.config.database import AsyncSessionLocal
from src.infrastructure.persistence.article_repository_impl import ArticleRepositoryImpl
from src.domain.value_objects.source_type import SourceType
from src.domain.entities.article import Article
from src.config.models_config import get_models_config

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def format_section_header(title: str, char: str = "=", width: int = 80) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü–∏–∏."""
    return f"\n{char * width}\n{title}\n{char * width}"


def format_subsection(title: str, width: int = 80) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥—Ä–∞–∑–¥–µ–ª."""
    return f"\n{'-' * width}\n{title}\n{'-' * width}"


def format_table_row(label: str, value: Any, width: int = 80) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É —Ç–∞–±–ª–∏—Ü—ã."""
    label_str = f"  {label}:"
    value_str = str(value)
    dots = width - len(label_str) - len(value_str)
    return f"{label_str}{' ' * dots}{value_str}"


def create_article_from_data(data: Dict[str, Any]) -> Article:
    """–°–æ–∑–¥–∞—Ç—å –æ–±—ä–µ–∫—Ç Article –∏–∑ —Å–ª–æ–≤–∞—Ä—è –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä—Å–µ—Ä–∞."""
    article = Article(
        id=uuid.uuid4(),
        title=data.get('title', ''),
        content=data.get('content', ''),
        url=data.get('url', ''),
        source=SourceType.HABR,  # –ù–ï source_type!
        author=data.get('author'),
        published_at=data.get('published_at'),
        tags=data.get('tags', []),
        hubs=data.get('hubs', [])
    )
    return article


def check_llm_provider() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞."""
    try:
        config = get_models_config()
        provider = config.get_provider()

        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {provider.value}")

        if provider.value == "openrouter":
            api_key = os.getenv("OPENROUTER_API_KEY")
            if not api_key:
                logger.error("OPENROUTER_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                return False

            if "YOUR-KEY-HERE" in api_key:
                logger.error("–ó–∞–º–µ–Ω–∏—Ç–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä API –∫–ª—é—á–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π")
                return False

            logger.info(f"OpenRouter API –∫–ª—é—á: {api_key[:25]}...")

            try:
                from src.infrastructure.ai.llm_provider import LLMProviderFactory
                test_config = config.get_llm_config("classifier")
                test_provider = LLMProviderFactory.create(test_config)
                logger.info("‚úì OpenRouter –ø—Ä–æ–≤–∞–π–¥–µ—Ä OK")
                return True
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ OpenRouter: {e}")
                return False

        elif provider.value == "ollama":
            try:
                from src.infrastructure.ai.llm_provider import LLMProviderFactory
                test_config = config.get_llm_config("classifier")
                test_provider = LLMProviderFactory.create(test_config)
                logger.info("‚úì Ollama –ø—Ä–æ–≤–∞–π–¥–µ—Ä OK")
                return True
            except Exception as e:
                logger.error(f"Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç: {e}")
                return False

        else:
            logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {provider.value}")
            return False

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {e}")
        return False


async def full_pipeline(
        limit: int = 10,
        hubs: str = "",
        verbose: bool = False,
        min_relevance: int = 5,
        debug: bool = False
):
    """–ü–æ–ª–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç–µ–π."""
    if debug:
        logging.getLogger().setLevel(logging.DEBUG)

    pipeline_start = time.time()

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    print(format_section_header("–ü–û–õ–ù–´–ô –ö–û–ù–í–ï–ô–ï–† –û–ë–†–ê–ë–û–¢–ö–ò –°–¢–ê–¢–ï–ô"))
    print(format_table_row("–í–µ—Ä—Å–∏—è", "3.3.0 (OpenRouter/Ollama)"))
    print(format_table_row("–ó–∞–ø—É—â–µ–Ω", datetime.now().strftime("%Y-%m-%d %H:%M:%S")))
    print(format_table_row("–õ–∏–º–∏—Ç —Å—Ç–∞—Ç–µ–π", limit))
    print(format_table_row("–¶–µ–ª–µ–≤—ã–µ —Ö–∞–±—ã", hubs if hubs else "–í—Å–µ"))
    print(format_table_row("–ú–∏–Ω. —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å", f"{min_relevance}/10"))

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–æ–≤...")

    try:
        scraper = HabrScraperService()
        logger.info("‚úì HabrScraperService")

        orchestrator = AIOrchestrator()
        logger.info("‚úì AIOrchestrator")

        qdrant = QdrantService()
        logger.info("‚úì QdrantService")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º
    print(format_subsection("–ü–†–û–í–ï–†–ö–ê –°–ò–°–¢–ï–ú–´"))

    if not check_llm_provider():
        return

    config = get_models_config()
    provider = config.get_provider()
    logger.info(f"‚úì LLM: {provider.value.upper()}")

    try:
        async with AsyncSessionLocal() as test_session:
            from sqlalchemy import text
            await test_session.execute(text("SELECT 1"))
        logger.info("‚úì PostgreSQL: OK")
    except Exception as e:
        logger.error(f"PostgreSQL –æ—à–∏–±–∫–∞: {e}")
        return

    logger.info("‚úì Qdrant: OK")

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    print(format_subsection("–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø AI"))

    profile = os.getenv("LLM_PROFILE", "free_openrouter")
    sample_config = config.get_llm_config("classifier")

    print(format_table_row("–ü—Ä–æ–≤–∞–π–¥–µ—Ä", provider.value.upper()))
    print(format_table_row("–ü—Ä–æ—Ñ–∏–ª—å", profile))
    print(format_table_row("–ú–æ–¥–µ–ª—å", sample_config.model))

    if provider.value == "openrouter":
        if "free" in profile.lower() or ":free" in sample_config.model:
            print(format_table_row("–°—Ç–æ–∏–º–æ—Å—Ç—å", "üÜì –ë–ï–°–ü–õ–ê–¢–ù–û"))
        else:
            print(format_table_row("–°—Ç–æ–∏–º–æ—Å—Ç—å", "üí∞ –ü–ª–∞—Ç–Ω–∞—è –º–æ–¥–µ–ª—å"))

    # –ü–∞—Ä—Å–∏–Ω–≥
    print(format_section_header("–§–ê–ó–ê 1: –ü–ê–†–°–ò–ù–ì"))

    hubs_list = [h.strip() for h in hubs.split(',')] if hubs else []
    parse_limit = limit * 3

    scrape_start = time.time()
    articles_data = await scraper._scrape_articles(parse_limit, hubs_list)
    scrape_time = time.time() - scrape_start

    logger.info(f"–°–ø–∞—Ä—Å–µ–Ω–æ: {len(articles_data)} –∑–∞ {scrape_time:.2f}—Å")

    if not articles_data:
        print("–°—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ë–î
    print(format_section_header("–§–ê–ó–ê 2: –í–ê–õ–ò–î–ê–¶–ò–Ø –ë–î"))

    async with AsyncSessionLocal() as session:
        repo = ArticleRepositoryImpl(session)

        urls = [d['url'] for d in articles_data]
        existing = await repo.get_existing_urls(urls)
        new_articles_data = [d for d in articles_data if d['url'] not in existing][:limit]

        print(format_table_row("–°–ø–∞—Ä—Å–µ–Ω–æ", len(articles_data)))
        print(format_table_row("–í –ë–î", len(existing)))
        print(format_table_row("–ù–æ–≤—ã—Ö", len(new_articles_data)))

        if not new_articles_data:
            print("–ù–µ—Ç –Ω–æ–≤—ã—Ö —Å—Ç–∞—Ç–µ–π")
            return

        # AI –æ–±—Ä–∞–±–æ—Ç–∫–∞
        print(format_section_header("–§–ê–ó–ê 3: AI –û–ë–†–ê–ë–û–¢–ö–ê"))

        stats = {
            'total_scraped': len(articles_data),
            'processed': 0,
            'saved_to_db': 0,
            'saved_to_qdrant': 0,
            'low_relevance': 0,
            'errors': 0,
            'processing_times': []
        }

        pbar = tqdm(total=len(new_articles_data), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞") if HAS_TQDM else None

        for i, data in enumerate(new_articles_data, 1):
            try:
                start = time.time()

                # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç Article
                article = create_article_from_data(data)

                # AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ - –ø–µ—Ä–µ–¥–∞—ë–º –æ–±—ä–µ–∫—Ç Article!
                processed_article = orchestrator.process_article(
                    article=article,
                    verbose=verbose,
                    min_relevance=min_relevance
                )

                if processed_article is None:
                    stats['errors'] += 1
                    if pbar:
                        pbar.update(1)
                    continue

                score = processed_article.relevance_score or 0
                stats['processed'] += 1

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î
                # –î–æ–±–∞–≤–ª—è–µ–º AI –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ processed_article
                if not hasattr(processed_article, 'metadata') or processed_article.metadata is None:
                    processed_article.metadata = {}

                processed_article.metadata.update({
                    'ai_summary': processed_article.editorial_teaser if hasattr(processed_article,
                                                                                'editorial_teaser') else None,
                    'editorial_title': processed_article.editorial_title if hasattr(processed_article,
                                                                                    'editorial_title') else None,
                    'relevance_score': score,
                    'relevance_reason': processed_article.relevance_reason if hasattr(processed_article,
                                                                                      'relevance_reason') else None,
                    'is_news': processed_article.is_news if hasattr(processed_article, 'is_news') else None,
                })

                # repo.save –ø—Ä–∏–Ω–∏–º–∞–µ—Ç Article –Ω–∞–ø—Ä—è–º—É—é
                db_article = await repo.save(processed_article)
                await session.commit()
                stats['saved_to_db'] += 1

                # Qdrant
                if score >= min_relevance:
                    qdrant.add_article(str(db_article.id), db_article.title, db_article.content or "")
                    stats['saved_to_qdrant'] += 1
                else:
                    stats['low_relevance'] += 1

                elapsed = time.time() - start
                stats['processing_times'].append(elapsed)

                if pbar:
                    pbar.update(1)
                    pbar.set_postfix({'score': f"{score}/10", 'time': f"{elapsed:.1f}s"})

                if verbose:
                    print(f"\n   [{i}] {processed_article.title[:50]}...")
                    print(f"       Score: {score}/10 | Teaser: {(processed_article.editorial_teaser or '')[:60]}...")

            except Exception as e:
                stats['errors'] += 1
                logger.error(f"–û—à–∏–±–∫–∞ {i}: {e}")
                if debug:
                    import traceback
                    traceback.print_exc()
                if pbar:
                    pbar.update(1)

        if pbar:
            pbar.close()

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_time = time.time() - pipeline_start

    print(format_section_header("–†–ï–ó–£–õ–¨–¢–ê–¢–´"))
    print(format_table_row("–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ", stats['processed']))
    print(format_table_row("–í –ë–î", stats['saved_to_db']))
    print(format_table_row("–í Qdrant", stats['saved_to_qdrant']))
    print(format_table_row("–ù–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å", stats['low_relevance']))
    print(format_table_row("–û—à–∏–±–æ–∫", stats['errors']))

    if stats['processing_times']:
        avg = sum(stats['processing_times']) / len(stats['processing_times'])
        print(format_table_row("–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è", f"{avg:.2f}—Å"))

    print(format_table_row("–û–±—â–µ–µ –≤—Ä–µ–º—è", f"{total_time:.2f}—Å"))

    if stats['errors'] == 0:
        print(format_table_row("–°—Ç–∞—Ç—É—Å", "‚úÖ –£–°–ü–ï–•"))
    else:
        print(format_table_row("–°—Ç–∞—Ç—É—Å", "‚ö†Ô∏è  –° –û–®–ò–ë–ö–ê–ú–ò"))

    print("=" * 80)


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç–∞—Ç–µ–π')
    parser.add_argument('limit', type=int, nargs='?', default=10)
    parser.add_argument('hubs', type=str, nargs='?', default="")
    parser.add_argument('--verbose', '-v', action='store_true')
    parser.add_argument('--debug', action='store_true')
    parser.add_argument('--min-relevance', type=int, default=5)

    args = parser.parse_args()

    try:
        asyncio.run(full_pipeline(
            limit=args.limit,
            hubs=args.hubs,
            verbose=args.verbose,
            min_relevance=args.min_relevance,
            debug=args.debug
        ))
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  –ü—Ä–µ—Ä–≤–∞–Ω–æ")
        sys.exit(1)
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)